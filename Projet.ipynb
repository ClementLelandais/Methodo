{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc54c74-ed7a-48b3-a6cd-a844e0d3ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation des bilbiothèques\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Chargement des données\n",
    "# nb de solutions : regrouper ?\n",
    "\n",
    "url = './data_G/data_G.solution'\n",
    "df = pd.read_csv(url, sep='\\s+', header=None)\n",
    "df.head()\n",
    "\n",
    "#Teste si les colonnes contiennent des valeurs nulles\n",
    "#df.columns[df.isnull().any()]\n",
    "#df.shape\n",
    "\n",
    "#def clean_data(data):\n",
    "    #\"\"\"\n",
    "    #Regarde si des nan sont présentes dans des colonnes, si oui, les supprimer.\n",
    "    #Détecter s'il s'agit d'une classification ou d'une régression et appliquer le bon algorithme, \n",
    "    #en choisissant les bons paramètres.\n",
    "    #Supprimer les variables peu informatives ou fortement corélées (TD maths, corrélation accumulatives...).\n",
    "    #Appliquer éventuellement des techniques de réduction dimensionnelle (PCA, t-SNE) pour visualiser et décider\n",
    "    #\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6a2d54-f4f4-4196-a68d-89f492f8858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des données du dossier A : (34190, 24)\n",
      "     0   1   2    3   4         5    6    7   8   9   ...  14  15    16  17  \\\n",
      "0  11.0  45  34  1.0  55  127921.0  1.0  1.0   0   4  ...   9   1     0   1   \n",
      "1   4.0  50  41  1.0  60  231619.0  1.0  2.0   0   2  ...  10   5     0   1   \n",
      "2   2.0  40  36  1.0  26  119941.0  1.0  1.0   0   4  ...   9   7     0   1   \n",
      "3   1.0  40  26  1.0  38  215766.0  1.0  1.0   0   2  ...  10   2  3103   1   \n",
      "4   1.0  40  28  1.0  38  170525.0  1.0  1.0   0   7  ...  11   2     0   2   \n",
      "\n",
      "   18        19  20   21  22  23  \n",
      "0   3  241885.0   0  1.0  44   4  \n",
      "1   3  104334.0   0  1.0  59   9  \n",
      "2   2   77953.0   0  1.0  44  15  \n",
      "3   3  167350.0   0  1.0  31   4  \n",
      "4   2  109857.0   0  1.0  18   1  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Dimensions des solutions : (34190, 3)\n",
      "   0  1  2\n",
      "0  1  1  1\n",
      "1  1  1  0\n",
      "2  0  1  1\n",
      "3  1  1  0\n",
      "4  1  0  1\n",
      "Nombre de features annoncées : 24\n",
      "Exemples de types de features : ['Categorical', 'Numerical', 'Numerical', 'Categorical', 'Numerical']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Lecture des features (.data) dans un DataFrame pandas\n",
    "data_df = pd.read_csv('./data_A/data_A.data', sep='\\s+', header=None, na_values='NaN')\n",
    "print(\"Dimensions des données du dossier A :\", data_df.shape)\n",
    "print(data_df.head())\n",
    "# Lecture des cibles (.solution)\n",
    "solution_df = pd.read_csv('./data_A/data_A.solution', sep='\\s+', header=None)\n",
    "print(\"Dimensions des solutions :\", solution_df.shape)\n",
    "print(solution_df.head())\n",
    "# Lecture des types (.type)\n",
    "with open('./data_A/data_A.type', 'r') as f:\n",
    "    feature_types = [line.strip() for line in f.readlines()]\n",
    "print(\"Nombre de features annoncées :\", len(feature_types))\n",
    "print(\"Exemples de types de features :\", feature_types[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ea646f-16ec-4a48-a523-adb4794f4c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes par colonne :\n",
      "0     1959\n",
      "3      614\n",
      "6     1952\n",
      "7     1941\n",
      "13     590\n",
      "21    1979\n",
      "dtype: int64\n",
      "Taille du train set : (27352, 24) | Taille du set de validation : (6838, 24)\n"
     ]
    }
   ],
   "source": [
    "# Détection des valeurs manquantes par colonne\n",
    "missing_counts = data_df.isna().sum()\n",
    "print(\"Valeurs manquantes par colonne :\")\n",
    "print(missing_counts[missing_counts > 0])\n",
    "# Exemple: séparation entraînement/validation (20% validation)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data_df\n",
    "# features\n",
    "y = solution_df # cibles (DataFrame ou Series)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Taille du train set :\", X_train.shape, \"| Taille du set de validation :\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2345fa2-a874-4d80-9b21-715d8e19edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des features après prétraitement : (27352, 215)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Séparation des colonnes numériques et catégorielles d’après feature_types\n",
    "numeric_features = [i for i, t in enumerate(feature_types) if t == 'Numerical']\n",
    "categorical_features = [i for i, t in enumerate(feature_types) if t == 'Categorical']\n",
    "# Transformer pour les numériques: impute (moyenne) puis standardisation -> remplace NaN par la moyenne de la colonne\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),('scaler', StandardScaler())])\n",
    "\n",
    "# Transformer pour les catégorielles : impute (remplace NaN par la catégorie la plus fréquente) puis one-hot encode et ignore si catégorie inconnue en test\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combinaison des transformations par colonnes\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_val_prepared = preprocessor.transform(X_val)\n",
    "print(\"Dimensions des features après prétraitement :\", X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49e888f-ef26-4332-bb44-49f0192f81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  0.853855903285561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Préparation des données pour entraînement (on suppose X_train_prepared déjà calculé via preprocessor)\n",
    "X_train_arr = X_train_prepared # peut être une array numpy ou un sparse matrix selon onehot\n",
    "X_val_arr = X_val_prepared\n",
    "# Détection du cas multi-label vs multi-class vs binaire\n",
    "y_train_arr = y_train.values # convert DataFrame to numpy array\n",
    "y_val_arr = y_val.values\n",
    "multilabel = False\n",
    "if y_train_arr.ndim > 1 and y_train_arr.shape[1] > 1:\n",
    "    multilabel = True\n",
    "# Définition des modèles à tester\n",
    "models = {}\n",
    "# Pour logistic regression, si multi-label, on encapsule dans OneVsRest (OVR)\n",
    "if multilabel:\n",
    "    models['LogisticRegression_OVR'] = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "else:\n",
    "    models['LogisticRegression'] = LogisticRegression(max_iter=1000)\n",
    "    models['RandomForest'] = RandomForestClassifier(n_estimators=200)\n",
    "    models['HistGradientBoosting'] = HistGradientBoostingClassifier()\n",
    "# Entraînement et évaluation sur le set de validation\n",
    "best_model_name = None\n",
    "best_score = -1\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_arr, y_train_arr)\n",
    "    # Prédiction sur validation\n",
    "    y_pred = clf.predict(X_val_arr)\n",
    "    # Si multi-label, accuracy_score n’est pas directement adaptée (on pourrait calculer par étiquette ou utiliser jaccard)\n",
    "    # Ici on calcule l'accuracy globale moyenne pour simplifier\n",
    "    if multilabel:\n",
    "        score = (y_pred == y_val_arr).mean()\n",
    "        best_model = clf\n",
    "        print(\"Score : \", score)\n",
    "    else:\n",
    "        score = accuracy_score(y_val_arr, y_pred)\n",
    "        print(f\"{name} accuracy = {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model_name = name\n",
    "            best_model = clf\n",
    "            print(\"Meilleur modèle sélectionné :\", best_model_name, \"avec score validation =\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99115e5e-4b18-4d97-a306-653d531d484f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Supposons best_model et best_model_name obtenus précédemment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y_pred_val = \u001b[43mbest_score\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(X_val_arr)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multilabel:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Pour chaque étiquette, calculer F1-score\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRapport de classification multi-label (par étiquette) :\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Supposons best_model et best_model_name obtenus précédemment\n",
    "y_pred_val = best_score.predict(X_val_arr)\n",
    "if multilabel:\n",
    "    # Pour chaque étiquette, calculer F1-score\n",
    "    print(\"Rapport de classification multi-label (par étiquette) :\")\n",
    "    for i in range(y_val_arr.shape[1]):\n",
    "        print(f\"Étiquette {i}:\")\n",
    "        print(classification_report(y_val_arr[:, i], y_pred_val[:, i]))\n",
    "else:\n",
    "    print(\"Rapport de classification :\")\n",
    "    print(classification_report(y_val_arr, y_pred_val))\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix(y_val_arr, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087375d1-49b5-4be8-8999-eeeb3b05fdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
