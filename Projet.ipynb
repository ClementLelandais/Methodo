{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc54c74-ed7a-48b3-a6cd-a844e0d3ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  0\n",
       "3  0\n",
       "4  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation des bilbioth√®ques\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Chargement des donn√©es\n",
    "# nb de solutions : regrouper ?\n",
    "\n",
    "url = './data_D/data_D.solution'\n",
    "df = pd.read_csv(url, sep='\\s+', header=None)\n",
    "df.head()\n",
    "\n",
    "#Teste si les colonnes contiennent des valeurs nulles\n",
    "#df.columns[df.isnull().any()]\n",
    "#df.shape\n",
    "\n",
    "#def clean_data(data):\n",
    "    #\"\"\"\n",
    "    #Regarde si des nan sont pr√©sentes dans des colonnes, si oui, les supprimer.\n",
    "    #D√©tecter s'il s'agit d'une classification ou d'une r√©gression et appliquer le bon algorithme, \n",
    "    #en choisissant les bons param√®tres.\n",
    "    #Supprimer les variables peu informatives ou fortement cor√©l√©es (TD maths, corr√©lation accumulatives...).\n",
    "    #Appliquer √©ventuellement des techniques de r√©duction dimensionnelle (PCA, t-SNE) pour visualiser et d√©cider\n",
    "    #\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6a2d54-f4f4-4196-a68d-89f492f8858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des donn√©es du dossier A : (2984, 144)\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  134  135  136  137  \\\n",
      "0    1    0    0    0    0    1    1    0    1    0  ...    1    0    1    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    1   \n",
      "2    0    0    0    0    0    1    0    0    0    0  ...    0    0    1    0   \n",
      "3    0    0    0    0    0    1    0    0    1    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    1    0    1    0  ...    0    0    0    1   \n",
      "\n",
      "   138  139  140  141  142  143  \n",
      "0    1    0    1    0    0    0  \n",
      "1    0    1    0    0    0    0  \n",
      "2    0    1    0    0    0    1  \n",
      "3    0    0    0    1    0    0  \n",
      "4    0    0    0    1    0    0  \n",
      "\n",
      "[5 rows x 144 columns]\n",
      "Dimensions des solutions : (2984, 1)\n",
      "   0\n",
      "0  1\n",
      "1  1\n",
      "2  0\n",
      "3  0\n",
      "4  1\n",
      "Nombre de features annonc√©es : 144\n",
      "Exemples de types de features : ['Binary', 'Binary', 'Binary', 'Binary', 'Binary']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Lecture des features (.data) dans un DataFrame pandas\n",
    "data_df = pd.read_csv('./data_D/data_D.data', sep='\\s+', header=None, na_values='NaN')\n",
    "print(\"Dimensions des donn√©es du dossier A :\", data_df.shape)\n",
    "print(data_df.head())\n",
    "# Lecture des cibles (.solution)\n",
    "solution_df = pd.read_csv('./data_D/data_D.solution', sep='\\s+', header=None)\n",
    "print(\"Dimensions des solutions :\", solution_df.shape)\n",
    "print(solution_df.head())\n",
    "# Lecture des types (.type)\n",
    "with open('./data_D/data_D.type', 'r') as f:\n",
    "    feature_types = [line.strip() for line in f.readlines()]\n",
    "print(\"Nombre de features annonc√©es :\", len(feature_types))\n",
    "print(\"Exemples de types de features :\", feature_types[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ea646f-16ec-4a48-a523-adb4794f4c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes par colonne :\n",
      "Series([], dtype: int64)\n",
      "Taille du train set : (2387, 144) | Taille du set de validation : (597, 144)\n"
     ]
    }
   ],
   "source": [
    "# D√©tection des valeurs manquantes par colonne\n",
    "missing_counts = data_df.isna().sum()\n",
    "print(\"Valeurs manquantes par colonne :\")\n",
    "print(missing_counts[missing_counts > 0])\n",
    "# Exemple: s√©paration entra√Ænement/validation (80% entrainement et 20% validation)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data_df\n",
    "\n",
    "y = solution_df \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Taille du train set :\", X_train.shape, \"| Taille du set de validation :\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2345fa2-a874-4d80-9b21-715d8e19edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des features apr√®s pr√©traitement : (2387, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# S√©paration des colonnes num√©riques et cat√©gorielles d‚Äôapr√®s feature_types\n",
    "numeric_features = [i for i, t in enumerate(feature_types) if t == 'Numerical']\n",
    "categorical_features = [i for i, t in enumerate(feature_types) if t == 'Categorical']\n",
    "# Transformer pour les num√©riques: impute (moyenne) puis standardisation -> remplace NaN par la moyenne de la colonne\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),('scaler', StandardScaler())])\n",
    "\n",
    "# Transformer pour les cat√©gorielles : impute (remplace NaN par la cat√©gorie la plus fr√©quente) puis one-hot encode et ignore si cat√©gorie inconnue en test\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combinaison des transformations par colonnes\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_val_prepared = preprocessor.transform(X_val)\n",
    "print(\"Dimensions des features apr√®s pr√©traitement :\", X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49e888f-ef26-4332-bb44-49f0192f81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entra√Ænement sans warnings...\n",
      "‚è≥ LogisticRegression...\n",
      "   Score: 0.7571\n",
      "‚è≥ RandomForest...\n",
      "   Score: 0.8023\n",
      "\n",
      "üìä RandomForest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77       288\n",
      "           1       0.76      0.91      0.83       309\n",
      "\n",
      "    accuracy                           0.80       597\n",
      "   macro avg       0.82      0.80      0.80       597\n",
      "weighted avg       0.82      0.80      0.80       597\n",
      "\n",
      "Confusion Matrix:\n",
      "[[197  91]\n",
      " [ 27 282]]\n",
      "\n",
      "‚úÖ Z√©ro warning ! Meilleur: RandomForest (0.8023)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)  # Cache warnings mineurs\n",
    "\n",
    "\n",
    "# ALIGNEMENT si n√©cessaire\n",
    "if 'X_train_arr' not in locals():\n",
    "    n_train = min(X_train.shape[0], len(y_train))\n",
    "    X_train_arr = X_train[:n_train]\n",
    "    y_train_arr = np.asarray(y_train)[:n_train].ravel()\n",
    "    n_val = min(X_val.shape[0], len(y_val))\n",
    "    X_val_arr = X_val[:n_val]\n",
    "    y_val_arr = np.asarray(y_val)[:n_val].ravel()\n",
    "\n",
    "multilabel = y_train_arr.ndim > 1\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': make_pipeline(\n",
    "        StandardScaler(), \n",
    "        LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)\n",
    "}\n",
    "\n",
    "best_model, best_name, best_score = None, None, -1\n",
    "for name, clf in models.items():\n",
    "    print(f\"{name}\")\n",
    "    clf.fit(X_train_arr, y_train_arr)\n",
    "    y_pred = clf.predict(X_val_arr)\n",
    "    score = accuracy_score(y_val_arr, y_pred)\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score, best_name, best_model = score, name, clf\n",
    "\n",
    "print(f\"\\nMeilleur : {best_name}:\")\n",
    "print(classification_report(y_val_arr, best_model.predict(X_val_arr)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val_arr, best_model.predict(X_val_arr)))\n",
    "\n",
    "print(f\"\\nMeilleur : {best_name} ({best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087375d1-49b5-4be8-8999-eeeb3b05fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77       288\n",
      "           1       0.76      0.91      0.83       309\n",
      "\n",
      "    accuracy                           0.80       597\n",
      "   macro avg       0.82      0.80      0.80       597\n",
      "weighted avg       0.82      0.80      0.80       597\n",
      "\n",
      "Matrice de confusion :\n",
      "[[197  91]\n",
      " [ 27 282]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred_val = best_model.predict(X_val_arr)\n",
    "if multilabel:\n",
    "    print(\"Rapport de classification multi-label (par √©tiquette) :\")\n",
    "    for i in range(y_val_arr.shape[1]):\n",
    "        print(f\"√âtiquette {i}:\")\n",
    "        print(classification_report(y_val_arr[:, i], y_pred_val[:, i]))\n",
    "else:\n",
    "    print(\"Rapport de classification :\")\n",
    "    print(classification_report(y_val_arr, y_pred_val))\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix(y_val_arr, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31aae5f5-7fe6-45fc-824f-94c94bbfbf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelques pr√©dictions :\n",
      " [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Poursuivant avec best_model obtenu\n",
    "# Pr√©dictions sur le set de test (ici X_val sert d'exemple de nouveau set)\n",
    "y_pred = best_model.predict(X_val_arr)\n",
    "print(\"Quelques pr√©dictions :\\n\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae78cec-551a-480a-94e2-aff5aa89d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF + Feature Selection: 0.8174\n",
      "Top 5 features: [12 39 18 14 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Feature selection \n",
    "selector = SelectKBest(f_classif, k=min(50, X_train_arr.shape[1]))\n",
    "X_train_sel = selector.fit_transform(X_train_arr, y_train_arr)\n",
    "X_val_sel = selector.transform(X_val_arr)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train_sel, y_train_arr)\n",
    "print(f\"RF + Feature Selection: {accuracy_score(y_val_arr, rf.predict(X_val_sel)):.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"Top 5 features:\", rf.feature_importances_.argsort()[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7c360-2799-46f9-ab0a-4f519fcc9b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
